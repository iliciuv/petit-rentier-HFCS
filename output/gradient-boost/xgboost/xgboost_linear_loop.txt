##### xgb.Booster
raw: 2.1 Kb 
call:
  xgb.train(params = params, data = dtrain, nrounds = 500)
params (as set within xgb.train):
  objective = "reg:squarederror", booster = "gblinear", eta = "0.3", alpha = "0", lambda = "0", validate_parameters = "TRUE"
xgb.attributes:
  niter
callbacks:
  cb.print.evaluation(period = print_every_n)
# of features: 21 
niter: 500
nfeatures : 21 
[1] "IMPORTANCE MATRIX:"
               Feature         Weight
 1:     riquezafinTRUE  242546.890625
 2:       renthog1High  209984.484375
 3:         capitalist  144569.046875
 4:        renthog1Low -139427.734375
 5: homeownerNon-Owner -109031.109375
 6:    `self-employed`   97365.507812
 7:            `35-44`  -95882.750000
 8:             `0-34`  -87461.367188
 9:               `75`   86035.062500
10:            `65-75`   70000.804688
11: homeownerHomeowner   66144.312500
12:             worker  -55506.539062
13:            `54-65`   42695.406250
14:            manager   42135.421875
15:        (Intercept)   41275.507812
16:     renthog1Middle   40874.957031
17:            `45-54`  -17679.435547
18:            retired   15604.682617
19:           inactive  -13828.785156
20:           sexWomen   -7839.090820
21:            sv_year      -3.974905
               Feature         Weight
