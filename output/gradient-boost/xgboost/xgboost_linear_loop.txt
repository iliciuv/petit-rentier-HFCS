##### xgb.Booster
raw: 2.1 Kb 
call:
  xgb.train(params = params, data = dtrain, nrounds = 500)
params (as set within xgb.train):
  objective = "reg:squarederror", booster = "gblinear", eta = "0.3", alpha = "0", lambda = "0", validate_parameters = "TRUE"
xgb.attributes:
  niter
callbacks:
  cb.print.evaluation(period = print_every_n)
# of features: 21 
niter: 500
nfeatures : 21 
[1] "IMPORTANCE MATRIX:"
               Feature         Weight
 1:     riquezafinTRUE  242547.171875
 2:       renthog1High  209584.406250
 3:         capitalist  145607.343750
 4:        renthog1Low -139832.375000
 5: homeownerNon-Owner -108696.039062
 6:    `self-employed`   98403.929688
 7:            `35-44`  -94991.031250
 8:               `75`   86928.484375
 9:             `0-34`  -86572.382812
10:            `65-75`   70892.687500
11: homeownerHomeowner   66477.156250
12:             worker  -54466.765625
13:            `54-65`   43588.199219
14:            manager   43173.964844
15:        (Intercept)   42000.628906
16:     renthog1Middle   40473.335938
17:            `45-54`  -16786.662109
18:            retired   16645.218750
19:           inactive  -12789.886719
20:           sexWomen   -7836.878906
21:            sv_year      -5.777349
               Feature         Weight
