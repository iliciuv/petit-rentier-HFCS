##### xgb.Booster
raw: 2.1 Kb 
call:
  xgb.train(params = params, data = dtrain, nrounds = 500)
params (as set within xgb.train):
  objective = "reg:squarederror", booster = "gblinear", eta = "0.3", alpha = "0", lambda = "0", validate_parameters = "TRUE"
xgb.attributes:
  niter
callbacks:
  cb.print.evaluation(period = print_every_n)
# of features: 21 
niter: 500
nfeatures : 21 
[1] "IMPORTANCE MATRIX:"
               Feature         Weight
 1:     riquezafinTRUE  242547.203125
 2:       renthog1High  208744.796875
 3:         capitalist  144137.406250
 4:        renthog1Low -140669.062500
 5: homeownerNon-Owner -108502.617188
 6:    `self-employed`   96932.851562
 7:            `35-44`  -94308.585938
 8:               `75`   87610.476562
 9:             `0-34`  -85888.710938
10:            `65-75`   71575.960938
11: homeownerHomeowner   66671.367188
12:             worker  -55938.593750
13:            `54-65`   44270.480469
14:        (Intercept)   41891.253906
15:            manager   41704.281250
16:     renthog1Middle   39636.687500
17:            `45-54`  -16105.151367
18:            retired   15173.250000
19:           inactive  -14260.553711
20:           sexWomen   -7838.406250
21:            sv_year      -4.932883
               Feature         Weight
