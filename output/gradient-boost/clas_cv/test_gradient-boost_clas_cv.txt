Stochastic Gradient Boosting 

6313 samples
   4 predictor
   2 classes: '0', '1' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 5051, 5050, 5051, 5050, 5050 
Resampling results across tuning parameters:

  interaction.depth  n.trees  Accuracy   Kappa    
  1                   50      0.8034215  0.0000000
  1                  100      0.8073812  0.0987616
  1                  150      0.8086481  0.1110371
  2                   50      0.8075397  0.1007009
  2                  100      0.8170448  0.1867451
  2                  150      0.8176781  0.2112317
  3                   50      0.8168862  0.1969472
  3                  100      0.8153027  0.2154715
  3                  150      0.8151443  0.2156105

Tuning parameter 'shrinkage' was held constant at a value
 of 0.1
Tuning parameter 'n.minobsinnode' was held constant
 at a value of 10
Accuracy was used to select the optimal model using
 the largest value.
The final values used for the model were n.trees =
 150, interaction.depth = 2, shrinkage = 0.1
 and n.minobsinnode = 10.
                                  var   rel.inf
renthogMiddle           renthogMiddle 26.517663
renthogHigh               renthogHigh 16.092962
classretired             classretired 11.648282
bage35-44                   bage35-44 10.942297
bage54-65                   bage54-65  9.349951
bage75                         bage75  6.101799
bage65-75                   bage65-75  5.684597
bage45-54                   bage45-54  4.761307
classmanager             classmanager  2.630690
classcapitalist       classcapitalist  1.863552
classself-employed classself-employed  1.690079
sexWomen                     sexWomen  1.585209
classinactive           classinactive  1.131614
[1] "Average Accuracy (Classification): 0.812116286796224"
< table of extent 0 x 2 >
[1] "Accuracy (Classification): NaN"
