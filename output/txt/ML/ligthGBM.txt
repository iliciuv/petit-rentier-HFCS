## LightGBM output for all waves/countries/implications joint.

[LightGBM] [Info] Number of positive: 213239, number of negative: 933508
[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013154 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 68
[LightGBM] [Info] Number of data points in the train set: 1146747, number of used features: 9
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.185951 -> initscore=-1.476536
[LightGBM] [Info] Start training from score -1.476536


[1] "LightGBM Accuracy: 0.875630806097596"


            Feature        Gain       Cover  Frequency
1:           sa0100 0.345692876 0.375867568 0.31878788
2: quintile.gwealth 0.275818339 0.155274601 0.06878788
3:            class 0.199058396 0.085234413 0.07757576
4:              age 0.095562926 0.133890781 0.13666667
5:            hsize 0.032172365 0.102658507 0.13939394
6: quintile.gincome 0.024345242 0.050328319 0.06969697
7:          edu_ref 0.017420683 0.059056254 0.08909091
8:             wave 0.006343394 0.029257822 0.06333333
9:       head_gendr 0.003585780 0.008431734 0.03666667